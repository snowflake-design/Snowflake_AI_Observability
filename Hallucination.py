import os
import pandas as pd
import time
import random
from snowflake.snowpark.context import get_active_session
from snowflake.snowpark.session import Session
from snowflake.cortex import complete
from trulens.core.otel.instrument import instrument
from trulens.otel.semconv.trace import SpanAttributes
from trulens.apps.app import TruApp
from trulens.connectors.snowflake import SnowflakeConnector
from trulens.core.run import Run, RunConfig
from opentelemetry import trace

# Toxicity detection setup
try:
    import warnings
    warnings.filterwarnings("ignore", message="Some weights of the model checkpoint.*were not used")
    
    from transformers import pipeline
    toxicity_classifier = pipeline("text-classification", model="s-nlp/roberta_toxicity_classifier")
    print("‚úÖ Toxicity classifier loaded successfully")
except Exception as e:
    print(f"‚ö†Ô∏è Could not load toxicity classifier: {e}")
    toxicity_classifier = None

# Enable TruLens OpenTelemetry tracing
os.environ["TRULENS_OTEL_TRACING"] = "1"

# Get Snowflake session
try:
    session = get_active_session()
    print("Using active Snowflake session")
except:
    print("Creating new Snowflake session...")
    session = Session.builder.configs(SNOWFLAKE_CONFIG).create()

print(f"Current context: {session.get_current_database()}.{session.get_current_schema()}")

class RAGApplication:
    def __init__(self):
        self.model = "mistral-large2"
        
        self.knowledge_base = {
            "machine learning": [
                "Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming.",
                "ML algorithms can identify patterns in large datasets and make predictions or decisions based on those patterns.",
                "Common types include supervised learning, unsupervised learning, and reinforcement learning."
            ],
            "cloud computing": [
                "Cloud computing delivers computing services over the internet including storage, processing power, and applications.",
                "Major benefits include scalability, cost-effectiveness, and accessibility from anywhere with internet connection.",
                "Popular cloud providers include AWS, Microsoft Azure, and Google Cloud Platform."
            ],
            "artificial intelligence": [
                "AI refers to computer systems that can perform tasks typically requiring human intelligence.",
                "AI encompasses machine learning, natural language processing, computer vision, and robotics.",
                "Applications include chatbots, recommendation systems, autonomous vehicles, and medical diagnosis."
            ]
        }

    def detect_toxicity(self, text: str) -> str:
        """Detect if text is toxic using HuggingFace classifier."""
        if toxicity_classifier is None:
            return "unknown"
        
        try:
            result = toxicity_classifier(text)
            label = result[0]['label']
            confidence = result[0]['score']
            
            if label == 'TOXIC' and confidence > 0.5:
                return "yes"
            else:
                return "no"
        except Exception as e:
            print(f"Error in toxicity detection: {e}")
            return "unknown"

    @instrument(
        span_type=SpanAttributes.SpanType.RETRIEVAL,
        attributes={
            SpanAttributes.RETRIEVAL.QUERY_TEXT: "query",
            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: "return",
        }
    )
    def retrieve_context(self, query: str) -> list:
        """Retrieve relevant text from knowledge base."""
        # Get current span for adding custom attributes
        current_span = trace.get_current_span()
        
        query_lower = query.lower()
        retrieved_contexts = []
        
        # Add custom span attributes using OpenTelemetry API
        try:
            current_span.set_attribute("custom.retrieval_query", query)
            current_span.set_attribute("custom.retrieval_timestamp", str(time.time()))
            current_span.set_attribute("custom.query_length", len(query))
            print(f"‚úÖ Added custom retrieval attributes")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add custom retrieval attributes: {e}")
        
        for topic, contexts in self.knowledge_base.items():
            if topic in query_lower:
                retrieved_contexts.extend(contexts)
                # Log the matched topic
                try:
                    current_span.set_attribute("custom.matched_topic", topic)
                    current_span.set_attribute("custom.topic_match_type", "exact")
                except Exception as e:
                    print(f"‚ö†Ô∏è Could not add topic attribute: {e}")
                break
        
        if not retrieved_contexts:
            retrieved_contexts = self.knowledge_base.get("artificial intelligence", [])
            try:
                current_span.set_attribute("custom.matched_topic", "artificial_intelligence_default")
                current_span.set_attribute("custom.topic_match_type", "fallback")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not add fallback topic attribute: {e}")
        
        # Log number of contexts found
        try:
            current_span.set_attribute("custom.contexts_found", len(retrieved_contexts))
            current_span.set_attribute("custom.retrieval_success", len(retrieved_contexts) > 0)
            
            # Add an event for successful retrieval
            current_span.add_event(
                "context_retrieval_complete",
                {
                    "contexts_count": len(retrieved_contexts),
                    "query_topic": query_lower,
                    "retrieval_method": "keyword_matching"
                }
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add context count attributes: {e}")
        
        print(f"üîç Retrieved {len(retrieved_contexts)} contexts")
        return retrieved_contexts

    @instrument(
        span_type=SpanAttributes.SpanType.GENERATION,
        attributes={
            SpanAttributes.GENERATION.QUERY_TEXT: "query",
            SpanAttributes.GENERATION.GENERATED_TEXT: "return",
        }
    )
    def generate_completion(self, query: str, context_str: list) -> str:
        """Generate answer from context by calling an LLM."""
        current_span = trace.get_current_span()
        
        context_text = "\n".join([f"- {ctx}" for ctx in context_str])
        
        prompt = f"""Based on the following context, answer the question:

Context:
{context_text}

Question: {query}

Answer:"""
        
        # Add custom generation attributes
        try:
            current_span.set_attribute("custom.llm_model", self.model)
            current_span.set_attribute("custom.prompt_length", len(prompt))
            current_span.set_attribute("custom.context_items", len(context_str))
            current_span.set_attribute("custom.generation_method", "snowflake_cortex")
            print(f"‚úÖ Added custom generation attributes")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add generation attributes: {e}")
        
        try:
            response = complete(self.model, prompt)
            
            # Log successful generation
            try:
                current_span.set_attribute("custom.generation_status", "success")
                current_span.set_attribute("custom.response_length", len(response))
                current_span.set_attribute("custom.tokens_estimated", len(response.split()))
                
                # Add generation success event
                current_span.add_event(
                    "llm_generation_complete",
                    {
                        "model": self.model,
                        "response_length": len(response),
                        "status": "success"
                    }
                )
                
            except Exception as e:
                print(f"‚ö†Ô∏è Could not add success attributes: {e}")
                
            print(f"ü§ñ Generated response ({len(response)} chars)")
            return response
            
        except Exception as e:
            # Log generation error
            try:
                current_span.set_attribute("custom.generation_status", "error")
                current_span.set_attribute("custom.error_message", str(e))
                current_span.set_attribute("custom.error_type", type(e).__name__)
                
                # Add error event
                current_span.add_event(
                    "llm_generation_failed",
                    {
                        "model": self.model,
                        "error": str(e),
                        "status": "failed"
                    }
                )
                
            except Exception as attr_error:
                print(f"‚ö†Ô∏è Could not add error attributes: {attr_error}")
            
            return f"Error generating response: {str(e)}"

    @instrument(
        span_type=SpanAttributes.SpanType.RECORD_ROOT,
        attributes={
            SpanAttributes.RECORD_ROOT.INPUT: "input_data",
            SpanAttributes.RECORD_ROOT.OUTPUT: "return",
        }
    )
    def answer_query(self, input_data, username: str = "unknown") -> str:
        """Main entry point for the RAG application."""
        current_span = trace.get_current_span()
        
        # Handle different input types
        if isinstance(input_data, dict):
            query = input_data.get('query', '')
            username = input_data.get('username', 'unknown')
        elif hasattr(input_data, 'get'):
            query = input_data.get('query', str(input_data))
            username = input_data.get('username', 'unknown')
        else:
            query = str(input_data)
        
        print(f"üîç Processing query from user: {username}")
        
        # Add custom span attributes for username and other metadata
        try:
            current_span.set_attribute("custom.username", username)
            current_span.set_attribute("custom.query_text", query)
            current_span.set_attribute("custom.query_length", len(query))
            current_span.set_attribute("custom.processing_start", str(time.time()))
            current_span.set_attribute("custom.session_id", f"session_{username}_{int(time.time())}")
            
            # Detect toxicity and add to span
            toxicity_result = self.detect_toxicity(query)
            current_span.set_attribute("custom.toxicity_detected", toxicity_result)
            current_span.set_attribute("custom.toxicity_check_enabled", toxicity_classifier is not None)
            
            # Check for special usernames
            special_users = ['abc', 'XYZ', 'KKK']
            current_span.set_attribute("custom.is_special_user", username in special_users)
            current_span.set_attribute("custom.user_type", "special" if username in special_users else "regular")
            
            print(f"‚úÖ Custom attributes added: username={username}, toxicity={toxicity_result}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add custom attributes: {e}")
        
        # Add initial processing event
        try:
            current_span.add_event(
                "rag_processing_started",
                {
                    "username": username,
                    "query_preview": query[:50],
                    "toxicity_detected": toxicity_result,
                    "processing_timestamp": str(time.time())
                }
            )
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add start event: {e}")
        
        # Detect toxicity for console logging
        toxicity_result = self.detect_toxicity(query)
        print(f"üõ°Ô∏è Toxicity check for '{query[:50]}...': {toxicity_result}")
        
        # Process the query
        context_str = self.retrieve_context(query)
        response = self.generate_completion(query, context_str)
        
        # Add final processing attributes
        try:
            current_span.set_attribute("custom.processing_complete", True)
            current_span.set_attribute("custom.processing_end", str(time.time()))
            current_span.set_attribute("custom.final_response_length", len(response))
            current_span.set_attribute("custom.context_used_count", len(context_str))
            current_span.set_attribute("custom.response_generated", len(response) > 0)
            
            # Add final completion event
            current_span.add_event(
                "rag_interaction_complete",
                {
                    "username": username,
                    "query": query[:100],  # truncated for brevity
                    "toxicity": toxicity_result,
                    "response_length": len(response),
                    "context_count": len(context_str),
                    "success": True
                }
            )
            print(f"‚úÖ Processing complete event added")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Could not add completion attributes: {e}")
        
        print(f"‚úÖ Response generated for user {username} (toxicity: {toxicity_result})")
        
        return response

# Initialize the RAG application
test_app = RAGApplication()

# Test basic functionality
print("Testing basic functionality...")
test_response = test_app.answer_query("What is machine learning?", "test_user")
print(f"Test successful: {test_response[:100] if test_response else 'No response'}...")

# Create Snowflake connector
connector = SnowflakeConnector(snowpark_session=session)

# Enhanced test dataset with usernames
usernames = ["abc", "XYZ", "KKK", "regular_user", "john_doe"]

test_data = pd.DataFrame({
    'query': [
        "What is machine learning?",
        "What are cloud computing benefits?", 
        "What are AI applications?",
        "How does artificial intelligence work?",
        "What is supervised learning?"
    ],
    'expected_answer': [
        "Machine learning enables computers to learn from data without explicit programming.",
        "Cloud computing provides scalability, cost-effectiveness, and accessibility.",
        "AI applications include chatbots, recommendation systems, and autonomous vehicles.",
        "AI systems can perform tasks typically requiring human intelligence.",
        "Supervised learning uses labeled data to train models."
    ],
    'username': [random.choice(usernames) for _ in range(5)]
})

print(f"Created dataset with {len(test_data)} test queries")
print("Dataset preview:")
print(test_data[['query', 'username']].to_string())

# Register the app for Snowflake AI Observability
app_name = f"rag_otel_custom_attrs_{int(time.time())}"
tru_app = TruApp(
    test_app,
    app_name=app_name, 
    app_version="v1.0",
    connector=connector,
    main_method=test_app.answer_query
)

print(f"Application registered successfully: {app_name}")

# Single run configuration
run_config = RunConfig(
    run_name=f"otel_custom_attrs_run_{int(time.time())}",
    description="Standard Snowflake AI Observability metrics with OpenTelemetry custom attributes",
    label="otel_custom_attrs_test",
    source_type="DATAFRAME",
    dataset_name="Test dataset with custom OpenTelemetry attributes",
    dataset_spec={
        "RETRIEVAL.QUERY_TEXT": "query",
        "RECORD_ROOT.INPUT": "query",
        "RECORD_ROOT.GROUND_TRUTH_OUTPUT": "expected_answer",
    },
    llm_judge_name="mistral-large2"
)

print(f"Run configuration created: {run_config.run_name}")

# Add run to TruApp
run = tru_app.add_run(run_config=run_config)
print("Run added successfully")

# Start the run and wait for completion
print("Starting run execution...")
run.start(input_df=test_data)
print("Run execution completed")

# Wait for invocation to complete
print("\n" + "="*60)
print("WAITING FOR INVOCATION TO COMPLETE")
print("="*60)

max_attempts = 60
attempt = 0

while attempt < max_attempts:
    status = run.get_status()
    print(f"Attempt {attempt + 1}: Status = {status}")
    
    if status in ["INVOCATION_COMPLETED", "INVOCATION_PARTIALLY_COMPLETED"]:
        print("‚úÖ INVOCATION COMPLETED - Ready to compute metrics!")
        break
    elif status == "INVOCATION_FAILED":
        print("‚ùå Invocation failed!")
        break
    else:
        time.sleep(15)
        attempt += 1

if attempt >= max_attempts:
    print("‚ö†Ô∏è Timeout waiting for completion, but trying metrics anyway...")

# Compute standard Snowflake AI Observability metrics
print("\n" + "="*60)
print("COMPUTING STANDARD SNOWFLAKE AI OBSERVABILITY METRICS")
print("="*60)

# Only standard metrics are supported in Snowflake AI Observability
standard_metrics = [
    "answer_relevance",
    "context_relevance", 
    "groundedness",
    "correctness"
]

successful_metrics = []
failed_metrics = []

for metric in standard_metrics:
    print(f"\n--- Computing {metric.upper()} ---")
    
    try:
        run.compute_metrics(metrics=[metric])
        print(f"‚úÖ {metric} computation initiated successfully")
        
        print(f"Waiting for {metric} computation to complete...")
        time.sleep(90)
        
        current_status = run.get_status()
        print(f"Status after {metric}: {current_status}")
        
        successful_metrics.append(metric)
        
    except Exception as e:
        print(f"‚ùå Error computing {metric}: {e}")
        failed_metrics.append(metric)
    
    print(f"Brief pause before next metric...")
    time.sleep(30)

# Custom data analysis summary
print("\n" + "="*60)
print("OPENTELEMETRY CUSTOM ATTRIBUTES SUMMARY")
print("="*60)

print("‚úÖ Custom attributes added using OpenTelemetry trace.get_current_span().set_attribute():")
print("   - custom.username: User who made the request")
print("   - custom.toxicity_detected: Toxicity analysis result")
print("   - custom.query_text: Original query text")
print("   - custom.query_length: Length of query")
print("   - custom.processing_start/end: Processing timestamps")
print("   - custom.session_id: Unique session identifier")
print("   - custom.is_special_user: Whether user is in special list")
print("   - custom.user_type: User classification (special/regular)")
print("   - custom.matched_topic: Which knowledge base topic matched")
print("   - custom.contexts_found: Number of retrieved contexts")
print("   - custom.llm_model: Model used for generation")
print("   - custom.response_length: Length of generated response")
print("   - custom.generation_status: Success/failure status")

print("\n‚úÖ Custom events added using current_span.add_event():")
print("   - rag_processing_started: When processing begins")
print("   - context_retrieval_complete: When context retrieval finishes")
print("   - llm_generation_complete: When LLM generation finishes")
print("   - rag_interaction_complete: When full interaction completes")

if toxicity_classifier:
    print("\nüõ°Ô∏è Toxicity analysis summary:")
    for idx, row in test_data.iterrows():
        toxicity = test_app.detect_toxicity(row['query'])
        print(f"   Query: '{row['query'][:50]}...' | User: {row['username']} | Toxic: {toxicity}")
else:
    print("‚ö†Ô∏è Toxicity classifier not available")

# Final results
print("\n" + "="*60)
print("FINAL RESULTS - SNOWFLAKE AI OBSERVABILITY WITH CUSTOM ATTRIBUTES")
print("="*60)
print(f"‚úÖ Successful standard metrics: {successful_metrics}")
print(f"‚ùå Failed metrics: {failed_metrics}")
print(f"Success rate: {len(successful_metrics)}/{len(standard_metrics)}")

final_status = run.get_status()
print(f"\nFinal run status: {final_status}")

print("\n" + "="*60)
print("KEY ACCOMPLISHMENTS")
print("="*60)
print("‚úÖ Proper OpenTelemetry custom attributes using trace.get_current_span().set_attribute()")
print("‚úÖ Custom events added using current_span.add_event()")
print("‚úÖ Username and toxicity data captured in OpenTelemetry spans")
print("‚úÖ Standard Snowflake AI Observability metrics computed")
print("‚úÖ All traces stored in Snowflake with both standard and custom data")
print("‚úÖ Removed incompatible TruLens feedback functions")

print("\nüìä View results in Snowsight:")
print("   Navigate to: AI & ML -> Evaluations")
print("   Look for app:", app_name)
print("   Standard metrics: answer_relevance, context_relevance, groundedness, correctness")
print("   Custom trace data: Click on individual records to see detailed traces")
print("   üîç Look for custom.* attributes in span details:")
print("      - custom.username (user who made the request)")
print("      - custom.toxicity_detected (toxicity analysis result)")
print("      - custom.matched_topic (retrieval topic)")
print("      - custom.llm_model (generation model)")
print("      - custom.processing_* (timestamps and metadata)")
print("      - custom.is_special_user (user classification)")
print("   üìä Custom events: Various events throughout the RAG pipeline")

print("\nüí° TECHNICAL IMPLEMENTATION:")
print("   üéØ OpenTelemetry: current_span.set_attribute() for custom attributes")
print("   üìä Custom events: current_span.add_event() for structured events")
print("   üõ°Ô∏è Toxicity & username: Captured in OpenTelemetry span metadata")
print("   ‚ö° Compatible with Snowflake AI Observability architecture")

print("\nüéâ SUCCESS: OpenTelemetry custom attributes implemented correctly!")
print("   Standard Snowflake AI Observability metrics + OpenTelemetry custom attributes")
print("   Username tracking and toxicity detection integrated into OpenTelemetry traces")
